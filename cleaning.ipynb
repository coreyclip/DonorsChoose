{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><strong>In This Notebook...</strong></h2><br />\n",
    "This is for data cleaning and engineering for our project.  Much inspiration received from <a href=\"https://www.kaggle.com/shivamb/extensive-text-data-feature-engineering/notebook\" target=\"_blank\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.layers import Input, Embedding\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "warnings.filterwarnings('ignore')\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# declare some strings\n",
    "id_column = 'id'\n",
    "missing_token = ' UNK '\n",
    "\n",
    "# read in our data, parse_dates=['column name'] will read that column as a datetime object, can take a boolean, list of integers / names, list of lists or a dictionary,\n",
    "# does different things depending on which one you use read the docs~\n",
    "train = pd.read_csv('../data/train.csv', parse_dates=['project_submitted_datetime'])\n",
    "test = pd.read_csv('../data/test.csv', parse_dates=['project_submitted_datetime'])\n",
    "hopes = pd.read_csv('../data/resources.csv').fillna(missing_token)\n",
    "\n",
    "# lets make a master df of the train and test data to make our lives easier!\n",
    "df = pd.concat([train,test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mathy Features\n",
    "+ Min, Max, Mean Price for resources requested\n",
    "+ Min Quantity, Max Quantity, Mean Quantity of resources requested\n",
    "+ Min Total Price, Max Total Price, Mean Total Price of resources requested\n",
    "+ Total Price of items requested by proposal\n",
    "+ Number of Unique Items Requested by proposal\n",
    "+ Quantity of items requested in proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A new column for total price\n",
    "hopes['total_price'] = hopes['quantity']*hopes['price']\n",
    "\n",
    "# Make an aggregate df to join to our normal df\n",
    "# the .agg method takes in a function, string, or a dictionary or list of strings or functions.  The dictionary keys will be column names upon which functions should be run\n",
    "# I named it after the horse in Shadow of the Colossus~ the description column is now a count of how many, so it can be renamed to (number of )items\n",
    "agro = {'description':'count', 'quantity':'sum', 'price':'sum', 'total_price':'sum'}\n",
    "aggregatedf = hopes.groupby('id').agg(agro).rename(columns={'description':'items'})\n",
    "\n",
    "# now lets use that string functionality of .agg to get the min, max, and mean values!\n",
    "for maths in ['min', 'max', 'mean']:\n",
    "    # romanized Japanese horse name from game, and that guy that changes names in ff because why not lets have fun with variable names they're just for here anyway\n",
    "    aguro = {'quantity':maths, 'price':maths, 'total_price':maths}\n",
    "    namingway = {'quantity':maths+'_quantity', 'price':maths+'_price', 'total_price':maths+'_total_price'}\n",
    "    \n",
    "    # do some aggregation and join it to our previously created df\n",
    "    temporary = hopes.groupby('id').agg(aguro).rename(columns=namingway).fillna(0)\n",
    "    aggregatedf = aggregatedf.join(temporary)\n",
    "# This didn't work whoops # aggregatedf = aggregatedf.join([hopes.groupby('id').agg({'quantity':maths, 'price':maths, 'total_price':maths}).rename(columns={'quantity':maths+'_quantity', 'price':maths+'_price', 'total_price':maths+'_total_price'}).fillna(0) for maths in ['min', 'max', 'mean']])\n",
    "\n",
    "# and finally give it the original description columns aggregated together with a space in between them\n",
    "aggregatedf = aggregatedf.join(hopes.groupby('id').agg({'description':lambda x:' '.join(x.values.astype(str))}).rename(columns={'description':'resource_description'}))\n",
    "\n",
    "# Join that together with our everything df and check it out\n",
    "df = df.join(aggregatedf, on='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great, now lets play with time!\n",
    "+ Year of submission\n",
    "+ Month of submission\n",
    "+ Year Day (1-365) of submission\n",
    "+ Month Day (1-31) of submission\n",
    "+ Week Day (1-7) of submission\n",
    "+ Hour of submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using datetime to make the above features\n",
    "df['Year'] = df['project_submitted_datetime'].dt.year\n",
    "df['Month'] = df['project_submitted_datetime'].dt.month\n",
    "df['Year_Day'] = df['project_submitted_datetime'].dt.dayofyear\n",
    "df['Month_Day'] = df['project_submitted_datetime'].dt.day\n",
    "df['Week_Day'] = df['project_submitted_datetime'].dt.weekday\n",
    "df['Hour'] = df['project_submitted_datetime'].dt.hour\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text based features\n",
    "+ Length of essays including spaces\n",
    "+ Length of project title\n",
    "+ Word count across essays\n",
    "+ Character count across essays\n",
    "+ Word density / average length of words used\n",
    "+ Punctuation count\n",
    "+ Uppercase count\n",
    "+ Title Word Count (Gotta Have This Case)\n",
    "+ Stopword Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fill empty values with missing token ' UNK '\n",
    "df['project_essay_3'] = df['project_essay_3'].fillna(missing_token)\n",
    "df['project_essay_4'] = df['project_essay_4'].fillna(missing_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 348 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get length of each essay and its title\n",
    "df['essay1_len'] = df['project_essay_1'].apply(len)\n",
    "df['essay2_len'] = df['project_essay_2'].apply(len)\n",
    "df['essay3_len'] = df['project_essay_3'].apply(len)\n",
    "df['essay4_len'] = df['project_essay_4'].apply(len)\n",
    "df['title_len'] = df['project_title'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Combine the essays into one string\n",
    "df['text'] = df.apply(lambda row: ' '.join([str(row['project_essay_1']),\n",
    "                                            str(row['project_essay_2']),\n",
    "                                            str(row['project_essay_3']),\n",
    "                                            str(row['project_essay_4'])]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get our delicious features from that massive text\n",
    "df['char_count'] = df['text'].apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "df['word density'] = df['char_count'] / (df['word_count'] + 1)\n",
    "df['punctuation_count'] = df['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in punctuation)))\n",
    "df['title_word_count'] = df['text'].apply(lambda x: len([word for word in x.split() if word.istitle()]))\n",
    "df['upper_case_word_count'] = df['text'].apply(lambda x: len([word for word in x.split() if word.isupper()]))\n",
    "df['stopword_count'] = df['text'].apply(lambda x: len([word for word in x.split() if word.lower() in stop_words]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP style features\n",
    "+ Article Polarity - Sentiment polarity\n",
    "+ Article Subjectivity - Sentiment subjectivity\n",
    "+ Noun Count - count of words that are nouns, the ones that name objects, people, etc...\n",
    "+ Verb Count - count of words that are verbs, the ones that tell you about moving like walk or think...\n",
    "+ Adjective Count - count of words that are adjectives, the ones that describe nouns like red or big...\n",
    "+ Adverb Count - count of words that are adverbs, the ones that describe adjectives or verbs and typically end with -ly\n",
    "+ Pronoun Count - count of words that are pronouns, the ones that replace other words like her or they"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# functions get polarity and subjectivity using TextBlob\n",
    "def get_polarity(text):\n",
    "    try:\n",
    "        textblob = TextBlob(unicode(text, 'utf-8'))\n",
    "        pol = textblob.sentiment.polarity\n",
    "    except:\n",
    "        pol = 0.0\n",
    "    return pol\n",
    "\n",
    "def get_subjectivity(text):\n",
    "    try:\n",
    "        textblob = TextBloob(unicode(text, 'utf-8'))\n",
    "        subj = textblob.sentiment.subjectivity\n",
    "    except:\n",
    "        subj = 0.0\n",
    "    return subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 333 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now lets apply those functions to our df\n",
    "df['polarity'] = df['text'].apply(get_polarity)\n",
    "df['subjectivity'] = df['text'].apply(get_subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/\" target=\"_blank\">NLTK Part of Speech Tags</a> <- Click me (don't get excited there's no R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make a dictionary for parts of speech\n",
    "pos_dict = {\n",
    "    'noun': ['NN', 'NNS', 'NNP', 'NNPS'], #singular, plural regular nouns, singular, plural proper nouns\n",
    "    'pron': ['PRP', 'PRP$', 'WP', 'WP$'], #personal pronouns, possessive personal, wh pronouns, possessive wh pronouns\n",
    "    'verb': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'], #verb base, past tense, gerund, past participle, singular present, 3rd person present\n",
    "    'adj': ['JJ', 'JJR', 'JJS'], #adjective, comparative, superlative\n",
    "    'adv': ['RB', 'RBR', 'RBS', 'WRB'] #adverb, compartive, superlative, wh- adverb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# function to retrieve the parts of speech tag counts\n",
    "def pos_check(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_dic[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 18min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# now lets use that function to make new columns each in their own cell because it takes a while\n",
    "df['noun_count'] = df['text'].apply(lambda x: pos_check(x, 'noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 17min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['verb_count'] = df['text'].apply(lambda x: pos_check(x, 'verb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 17min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['adj_count'] = df['text'].apply(lambda x: pos_check(x, 'adj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 17min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['adv_count'] = df['text'].apply(lambda x: pos_check(x, 'adv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 17min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['pron_count'] = df['text'].apply(lambda x: pos_check(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>...</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>Music &amp; The Arts, Health &amp; Sports</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p233823</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>We are looking to add some 3Doodler to our cla...</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My students need the 3doodler. We are an SEM s...</td>\n",
       "      <td>Math &amp; Science, Literacy &amp; Language</td>\n",
       "      <td>Applied Sciences, Literature &amp; Writing</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p185307</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>The student's project which is totally \\\"kid-i...</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>My students need balls and other activity equi...</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p013780</td>\n",
       "      <td>My students are athletes and students who are ...</td>\n",
       "      <td>For some reason in our kitchen the water comes...</td>\n",
       "      <td>UNK</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My students need a water filtration system for...</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                    project_essay_1  \\\n",
       "0  p036502  Most of my kindergarten students come from low...   \n",
       "1  p039565  Our elementary school is a culturally rich sch...   \n",
       "2  p233823  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "3  p185307  My students are the greatest students but are ...   \n",
       "4  p013780  My students are athletes and students who are ...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...            UNK    \n",
       "1  We strive to provide our diverse population of...            UNK    \n",
       "2  We are looking to add some 3Doodler to our cla...            UNK    \n",
       "3  The student's project which is totally \\\"kid-i...            UNK    \n",
       "4  For some reason in our kitchen the water comes...            UNK    \n",
       "\n",
       "  project_essay_4 project_grade_category  project_is_approved  \\\n",
       "0            UNK           Grades PreK-2                  1.0   \n",
       "1            UNK              Grades 3-5                  0.0   \n",
       "2            UNK              Grades 3-5                  1.0   \n",
       "3            UNK              Grades 3-5                  0.0   \n",
       "4            UNK              Grades 6-8                  1.0   \n",
       "\n",
       "                            project_resource_summary  \\\n",
       "0  My students need 6 Ipod Nano's to create and d...   \n",
       "1  My students need matching shirts to wear for d...   \n",
       "2  My students need the 3doodler. We are an SEM s...   \n",
       "3  My students need balls and other activity equi...   \n",
       "4  My students need a water filtration system for...   \n",
       "\n",
       "            project_subject_categories  \\\n",
       "0                  Literacy & Language   \n",
       "1    Music & The Arts, Health & Sports   \n",
       "2  Math & Science, Literacy & Language   \n",
       "3                      Health & Sports   \n",
       "4                      Health & Sports   \n",
       "\n",
       "            project_subject_subcategories     ...     title_word_count  \\\n",
       "0                                Literacy     ...                   21   \n",
       "1            Performing Arts, Team Sports     ...                   15   \n",
       "2  Applied Sciences, Literature & Writing     ...                   26   \n",
       "3                       Health & Wellness     ...                   31   \n",
       "4                       Health & Wellness     ...                   13   \n",
       "\n",
       "  upper_case_word_count stopword_count polarity  subjectivity noun_count  \\\n",
       "0                     7            151      0.0           0.0          0   \n",
       "1                     5             79      0.0           0.0          0   \n",
       "2                     6            103      0.0           0.0          0   \n",
       "3                     6            188      0.0           0.0          0   \n",
       "4                     2             98      0.0           0.0          0   \n",
       "\n",
       "   verb_count  adj_count  adv_count  pron_count  \n",
       "0           0          0          0           0  \n",
       "1           0          0          0           0  \n",
       "2           0          0          0           0  \n",
       "3           0          0          0           0  \n",
       "4           0          0          0           0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF style features\n",
    "+ 1-3 NGram TF-IDF for Article Text at word level\n",
    "+ 1-3 NGram TF-IDF for Project Title at word level\n",
    "+ 1-3 NGram TF-IDF for Resource Text at word level\n",
    "+ 1-3 NGram TF-IDF for Article Text at character level\n",
    "+ 1-3 NGram TF-IDF for Project Title at character level\n",
    "+ 1-3 NGram TF-IDF for Resource Text at character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['resource_text'] = df.apply(lambda row: ' '.join([str(row['resource_description']), str(row['project_resource_summary'])]), axis=1)\n",
    "\n",
    "article_text = list(df['text'].values)\n",
    "title_text = list(df['project_title'].values)\n",
    "resource_text = list(df['resource_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_csv('../data/everything.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word level tf-idf for article text\n",
    "vectorizer = TfidfVectorizer(max_features=2500, analyzer='word', stop_words='english', ngram_range=(1,3), dtype=np.float32)\n",
    "vectorizer.fit(article_text)\n",
    "article_word_tfidf = vectorizer.transform(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word level tf-idf for titles\n",
    "vectorizer = TfidfVectorizer(max_features=2500, analyzer='word', stop_words='english', ngram_range=(1,3), dtype=np.float32)\n",
    "vectorizer.fit(title_text)\n",
    "title_word_tfidf = vectorizer.transform(title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word level tf-idf for resource text\n",
    "vectorizer = TfidfVectorizer(max_features=2500, analyzer='word', stop_words='english', ngram_range=(1,3), dtype=np.float32)\n",
    "vectorizer.fit(resource_text)\n",
    "resource_word_tfidf = vectorizer.transform(resource_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a dictionary mapping tokens to their tfidf values\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "tfidf = pd.DataFrame(columns=['resource_word_tfidf']).from_dict(dict(tfidf), orient='index')\n",
    "tfidf.columns = ['resource_word_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.96 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_word_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>branches book</th>\n",
       "      <td>7.823436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaries dork diaries</th>\n",
       "      <td>7.802456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superbright</th>\n",
       "      <td>7.792129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dork diaries dork</th>\n",
       "      <td>7.785303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diaries dork</th>\n",
       "      <td>7.781908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>branches</th>\n",
       "      <td>7.622444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 amp 34</th>\n",
       "      <td>7.610950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34 18 34</th>\n",
       "      <td>7.610950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp 34 18</th>\n",
       "      <td>7.610950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper 12 amp</th>\n",
       "      <td>7.608097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34 18</th>\n",
       "      <td>7.605252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reeds</th>\n",
       "      <td>7.588350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leapfrog</th>\n",
       "      <td>7.582779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 34</th>\n",
       "      <td>7.555380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lakeshore fully washable</th>\n",
       "      <td>7.518240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          resource_word_tfidf\n",
       "branches book                        7.823436\n",
       "diaries dork diaries                 7.802456\n",
       "superbright                          7.792129\n",
       "dork diaries dork                    7.785303\n",
       "diaries dork                         7.781908\n",
       "branches                             7.622444\n",
       "12 amp 34                            7.610950\n",
       "34 18 34                             7.610950\n",
       "amp 34 18                            7.610950\n",
       "paper 12 amp                         7.608097\n",
       "34 18                                7.605252\n",
       "reeds                                7.588350\n",
       "leapfrog                             7.582779\n",
       "18 34                                7.555380\n",
       "lakeshore fully washable             7.518240"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 15 highest tf-idf from that list\n",
    "tfidf.sort_values(by=['resource_word_tfidf'], ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Character level tf-idfs\n",
    "# article text\n",
    "vectorizer = TfidfVectorizer(max_features=2000, analyzer='char', stop_words='english', ngram_range=(1,3), dtype=np.float32)\n",
    "vectorizer.fit(article_text)\n",
    "article_char_tfidf = vectorizer.transform(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# project title\n",
    "vectorizer = TfidfVectorizer(max_features=2000, analyzer='char', stop_words='english', ngram_range=(1,3), dtype=np.float32)\n",
    "vectorizer.fit(title_text)\n",
    "title_char_tfidf = vectorizer.transform(title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# resource text\n",
    "vectorizer = TfidfVectorizer(max_features=2000, analyzer='char', stop_words='english', ngram_range=(1,3), dtype=np.float32)\n",
    "vectorizer.fit(resource_text)\n",
    "resource_char_tfidf = vectorizer.transform(resource_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Be Continued...  My feeble attempts that weren't anywhere near all encompassing are below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athing = resource_df[resource_df['id'] == 'p069063']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athing_length = len(athing)\n",
    "for row in athing.itertuples():\n",
    "    print(round(row[3] * row[4], 2))\n",
    "athing_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumprice = []\n",
    "numbought = []\n",
    "avgprice = []\n",
    "\n",
    "for row in train_df.itertuples():\n",
    "    try:\n",
    "        df = resource_df[resource_df['id'] == row[1]]\n",
    "        df_length = len(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resource_scrape(idnum):\n",
    "    df = resource_df[resource_df['id'] == idnum]\n",
    "    try:\n",
    "        foo = [round(row[3] * row[4], 2) for row in df.itertuples()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['project_is_approved'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['teacher_number_of_previously_posted_projects'].value_counts() > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
