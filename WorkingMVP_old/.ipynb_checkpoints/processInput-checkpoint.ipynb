{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load the dictionary that you want to test: \n",
    "test_dict = np.load('test_dict.npy').item()\n",
    "\n",
    "# Load Data\n",
    "dtype = {\n",
    "    'id': str,\n",
    "    'teacher_id': str,\n",
    "    'teacher_prefix': str,\n",
    "    'school_state': str,\n",
    "    'project_submitted_datetime': str,\n",
    "    'project_grade_category': str,\n",
    "    'project_subject_categories': str,\n",
    "    'project_subject_subcategories': str,\n",
    "    'project_title': str,\n",
    "    'project_essay_1': str,\n",
    "    'project_essay_2': str,\n",
    "    'project_essay_3': str,\n",
    "    'project_essay_4': str,\n",
    "    'project_resource_summary': str,\n",
    "    'teacher_number_of_previously_posted_projects': int,\n",
    "    'project_is_approved': np.uint8,\n",
    "}\n",
    "data_path = os.path.join('',)\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'), dtype=dtype, low_memory=True)\n",
    "#test = pd.read_csv(os.path.join(data_path, 'test.csv'), dtype=dtype, low_memory=True)\n",
    "\n",
    "# chris's test_dict files:\n",
    "#train = pd.DataFrame.from_dict(test_dict, dtype=str)\n",
    "test = pd.DataFrame.from_dict(test_dict, dtype=str)\n",
    "test['teacher_number_of_previously_posted_projects'] = test['teacher_number_of_previously_posted_projects'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
      "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
      "2  p233823  a9b876a9252e08a55e3d894150f75ba3            Ms.           UT   \n",
      "3  p185307  525fdbb6ec7f538a48beebaa0a51b24f            Mr.           NC   \n",
      "4  p013780  a63b5547a7239eae4c1872670848e61a            Mr.           CA   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-11-18 14:45:59          Grades PreK-2   \n",
      "1        2017-04-26 15:57:28             Grades 3-5   \n",
      "2        2017-01-01 22:57:44             Grades 3-5   \n",
      "3        2016-08-12 15:42:11             Grades 3-5   \n",
      "4        2016-08-06 09:09:11             Grades 6-8   \n",
      "\n",
      "            project_subject_categories  \\\n",
      "0                  Literacy & Language   \n",
      "1    Music & The Arts, Health & Sports   \n",
      "2  Math & Science, Literacy & Language   \n",
      "3                      Health & Sports   \n",
      "4                      Health & Sports   \n",
      "\n",
      "            project_subject_subcategories  \\\n",
      "0                                Literacy   \n",
      "1            Performing Arts, Team Sports   \n",
      "2  Applied Sciences, Literature & Writing   \n",
      "3                       Health & Wellness   \n",
      "4                       Health & Wellness   \n",
      "\n",
      "                                       project_title  \\\n",
      "0                           Super Sight Word Centers   \n",
      "1                             Keep Calm and Dance On   \n",
      "2                              Lets 3Doodle to Learn   \n",
      "3  \\\"Kid Inspired\\\" Equipment to Increase Activit...   \n",
      "4   We need clean water for our culinary arts class!   \n",
      "\n",
      "                                     project_essay_1  \\\n",
      "0  Most of my kindergarten students come from low...   \n",
      "1  Our elementary school is a culturally rich sch...   \n",
      "2  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
      "3  My students are the greatest students but are ...   \n",
      "4  My students are athletes and students who are ...   \n",
      "\n",
      "                                     project_essay_2 project_essay_3  \\\n",
      "0  I currently have a differentiated sight word c...             NaN   \n",
      "1  We strive to provide our diverse population of...             NaN   \n",
      "2  We are looking to add some 3Doodler to our cla...             NaN   \n",
      "3  The student's project which is totally \\\"kid-i...             NaN   \n",
      "4  For some reason in our kitchen the water comes...             NaN   \n",
      "\n",
      "  project_essay_4                           project_resource_summary  \\\n",
      "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
      "1             NaN  My students need matching shirts to wear for d...   \n",
      "2             NaN  My students need the 3doodler. We are an SEM s...   \n",
      "3             NaN  My students need balls and other activity equi...   \n",
      "4             NaN  My students need a water filtration system for...   \n",
      "\n",
      "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
      "0                                            26                    1  \n",
      "1                                             1                    0  \n",
      "2                                             5                    1  \n",
      "3                                            16                    0  \n",
      "4                                            42                    1  \n",
      "(182080, 16) (1, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ucidataanalytics/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  quantity_sum  quantity_min  quantity_max  quantity_mean  \\\n",
      "0  p000001             7             1             2       1.750000   \n",
      "1  p000002            21             1             4       1.500000   \n",
      "2  p000003             4             1             1       1.000000   \n",
      "3  p000004            98             1             2       1.031579   \n",
      "4  p000005             8             1             3       2.000000   \n",
      "\n",
      "   quantity_std  price_count  price_sum  price_min  price_max  price_mean  \\\n",
      "0      0.500000            4     459.56      23.99     261.08  114.890000   \n",
      "1      0.854850           14     515.89       8.46     134.90   36.849286   \n",
      "2      0.000000            4     298.97      39.99     169.00   74.742500   \n",
      "3      0.175804           95    1113.69       1.60     401.54   11.723053   \n",
      "4      1.154701            4     485.99      54.08     323.75  121.497500   \n",
      "\n",
      "    price_std  price_<lambda>  mean_price  \n",
      "0  101.929679             4.0   65.651429  \n",
      "1   33.549557            13.0   24.566190  \n",
      "2   63.014906             3.0   74.742500  \n",
      "3   40.608577            36.0   11.364184  \n",
      "4  134.835000             2.0   60.748750  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:01<00:09,  1.99s/it]\r",
      " 33%|███▎      | 2/6 [00:02<00:04,  1.13s/it]\r",
      " 50%|█████     | 3/6 [00:02<00:02,  1.17it/s]\r",
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.40it/s]\r",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.55it/s]\r",
      "100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Preprocessing timestamp...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:06,  6.18s/it]\r",
      "2it [02:59, 89.93s/it]\r",
      "3it [03:21, 67.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(182080, 4878) (1, 4878)\n",
      "CPU times: user 2min 56s, sys: 54.4 s, total: 3min 50s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = pd.read_csv(os.path.join(data_path, 'resources.csv'))\n",
    "\n",
    "print(train.head())\n",
    "# print(test.head())\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "train['project_essay'] = train.apply(lambda row: ' '.join([\n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "test['project_essay'] = test.apply(lambda row: ' '.join([\n",
    "    str(row['project_essay_1']),\n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "\n",
    "# Extract features\n",
    "def extract_features(df):\n",
    "    df['project_title_len'] = df['project_title'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_1_len'] = df['project_essay_1'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_2_len'] = df['project_essay_2'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_3_len'] = df['project_essay_3'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_4_len'] = df['project_essay_4'].apply(lambda x: len(str(x)))\n",
    "    df['project_resource_summary_len'] = df['project_resource_summary'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    df['project_title_wc'] = df['project_title'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_1_wc'] = df['project_essay_1'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_2_wc'] = df['project_essay_2'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_3_wc'] = df['project_essay_3'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_4_wc'] = df['project_essay_4'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_resource_summary_wc'] = df['project_resource_summary'].apply(lambda x: len(str(x).split(' ')))\n",
    "  \n",
    "extract_features(train)\n",
    "extract_features(test)\n",
    "\n",
    "train.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4'], axis=1, inplace=True)\n",
    "test.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4'], axis=1, inplace=True)\n",
    "\n",
    "df_all = pd.concat([train, test], axis=0)\n",
    "gc.collect()\n",
    "\n",
    "res = pd.DataFrame(res[['id', 'quantity', 'price']].groupby('id').agg(\\\n",
    "    {\n",
    "        'quantity': [\n",
    "            'sum',\n",
    "            'min', \n",
    "            'max', \n",
    "            'mean', \n",
    "            'std', \n",
    "            # lambda x: len(np.unique(x)),\n",
    "        ],\n",
    "        'price': [\n",
    "            'count', \n",
    "            'sum', \n",
    "            'min',\n",
    "            'max', \n",
    "            'mean', \n",
    "            'std', \n",
    "            lambda x: len(np.unique(x)),\n",
    "        ]}\n",
    "    )).reset_index()\n",
    "res.columns = ['_'.join(col) for col in res.columns]\n",
    "res.rename(columns={'id_': 'id'}, inplace=True)\n",
    "res['mean_price'] = res['price_sum']/res['quantity_sum']\n",
    "# res['price_max_to_price_min'] = res['price_max']/res['price_min']\n",
    "# res['quantity_max_to_quantity_min'] = res['quantity_max']/res['quantity_min']\n",
    "\n",
    "print(res.head())\n",
    "train = train.merge(res, on='id', how='left')\n",
    "test = test.merge(res, on='id', how='left')\n",
    "del res\n",
    "gc.collect()\n",
    "\n",
    "# Preprocess columns with label encoder\n",
    "print('Label Encoder...')\n",
    "cols = [\n",
    "    'teacher_id', \n",
    "    'teacher_prefix', \n",
    "    'school_state', \n",
    "    'project_grade_category', \n",
    "    'project_subject_categories', \n",
    "    'project_subject_subcategories'\n",
    "]\n",
    "\n",
    "for c in tqdm(cols):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_all[c].astype(str))\n",
    "    train[c] = le.transform(train[c].astype(str))\n",
    "    test[c] = le.transform(test[c].astype(str))\n",
    "del le\n",
    "gc.collect()\n",
    "print('Done.')\n",
    "\n",
    "\n",
    "# Preprocess timestamp\n",
    "print('Preprocessing timestamp...')\n",
    "def process_timestamp(df):\n",
    "    df['year'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[0]))\n",
    "    df['month'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[1]))\n",
    "    df['date'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[2]))\n",
    "    df['day_of_week'] = pd.to_datetime(df['project_submitted_datetime']).dt.weekday\n",
    "    df['hour'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[0]))\n",
    "    df['minute'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[1]))\n",
    "    df['project_submitted_datetime'] = pd.to_datetime(df['project_submitted_datetime']).values.astype(np.int64)\n",
    "\n",
    "process_timestamp(train)\n",
    "process_timestamp(test)\n",
    "print('Done.')\n",
    "\n",
    "# Preprocess text\n",
    "print('Preprocessing text...')\n",
    "cols = [\n",
    "    'project_title', \n",
    "    'project_essay', \n",
    "    'project_resource_summary'\n",
    "]\n",
    "n_features = [\n",
    "    400, \n",
    "    4040, \n",
    "    400,\n",
    "]\n",
    "\n",
    "for c_i, c in tqdm(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=n_features[c_i],\n",
    "        norm='l2',\n",
    "        )\n",
    "    tfidf.fit(df_all[c])\n",
    "    tfidf_train = np.array(tfidf.transform(train[c]).toarray(), dtype=np.float16)\n",
    "    tfidf_test = np.array(tfidf.transform(test[c]).toarray(), dtype=np.float16)\n",
    "\n",
    "    for i in range(n_features[c_i]):\n",
    "        train[c + '_tfidf_' + str(i)] = tfidf_train[:, i]\n",
    "        test[c + '_tfidf_' + str(i)] = tfidf_test[:, i]\n",
    "        \n",
    "    del tfidf, tfidf_train, tfidf_test\n",
    "    gc.collect()\n",
    "    \n",
    "print('Done.')\n",
    "del df_all\n",
    "gc.collect()\n",
    "\n",
    "# Prepare data\n",
    "cols_to_drop = [\n",
    "    'id',\n",
    "    'teacher_id',\n",
    "    'project_title', \n",
    "    'project_essay', \n",
    "    'project_resource_summary',\n",
    "    'project_is_approved',\n",
    "]\n",
    "X = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "y = train['project_is_approved']\n",
    "X_test = test.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "id_test = test['id'].values\n",
    "feature_names = list(X.columns)\n",
    "print(X.shape, X_test.shape)\n",
    "\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "# Build the model\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=0)\n",
    "auc_buf = []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4878"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_title_len</th>\n",
       "      <th>project_essay_1_len</th>\n",
       "      <th>project_essay_2_len</th>\n",
       "      <th>...</th>\n",
       "      <th>project_resource_summary_tfidf_390</th>\n",
       "      <th>project_resource_summary_tfidf_391</th>\n",
       "      <th>project_resource_summary_tfidf_392</th>\n",
       "      <th>project_resource_summary_tfidf_393</th>\n",
       "      <th>project_resource_summary_tfidf_394</th>\n",
       "      <th>project_resource_summary_tfidf_395</th>\n",
       "      <th>project_resource_summary_tfidf_396</th>\n",
       "      <th>project_resource_summary_tfidf_397</th>\n",
       "      <th>project_resource_summary_tfidf_398</th>\n",
       "      <th>project_resource_summary_tfidf_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>404</td>\n",
       "      <td>1461764741000000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>249</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4878 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_grade_category  project_subject_categories  \\\n",
       "0                       3                          40   \n",
       "\n",
       "   project_subject_subcategories  project_submitted_datetime  school_state  \\\n",
       "0                            404         1461764741000000000             4   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  teacher_prefix  \\\n",
       "0                                             2               3   \n",
       "\n",
       "   project_title_len  project_essay_1_len  project_essay_2_len  \\\n",
       "0                 24                  249                  299   \n",
       "\n",
       "                  ...                  project_resource_summary_tfidf_390  \\\n",
       "0                 ...                                                 0.0   \n",
       "\n",
       "   project_resource_summary_tfidf_391  project_resource_summary_tfidf_392  \\\n",
       "0                                 0.0                                 0.0   \n",
       "\n",
       "   project_resource_summary_tfidf_393  project_resource_summary_tfidf_394  \\\n",
       "0                                 0.0                                 0.0   \n",
       "\n",
       "   project_resource_summary_tfidf_395  project_resource_summary_tfidf_396  \\\n",
       "0                                 0.0                                 0.0   \n",
       "\n",
       "   project_resource_summary_tfidf_397  project_resource_summary_tfidf_398  \\\n",
       "0                                 0.0                                 0.0   \n",
       "\n",
       "   project_resource_summary_tfidf_399  \n",
       "0                                 0.0  \n",
       "\n",
       "[1 rows x 4878 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model to predict\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# load model to predict\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except BaseException:\n",
    "    import pickle\n",
    "    \n",
    "\n",
    "print('Load model to predict')\n",
    "imported_model = pickle.load( open( \"model_v1.pkl\", \"rb\" ) )\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = imported_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92078649])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
