{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# Load Data\n",
    "dtype = {\n",
    "    'id': str,\n",
    "    'teacher_id': str,\n",
    "    'teacher_prefix': str,\n",
    "    'school_state': str,\n",
    "    'project_submitted_datetime': str,\n",
    "    'project_grade_category': str,\n",
    "    'project_subject_categories': str,\n",
    "    'project_subject_subcategories': str,\n",
    "    'project_title': str,\n",
    "    'project_essay_1': str,\n",
    "    'project_essay_2': str,\n",
    "    'project_essay_3': str,\n",
    "    'project_essay_4': str,\n",
    "    'project_resource_summary': str,\n",
    "    'teacher_number_of_previously_posted_projects': int,\n",
    "    'project_is_approved': np.uint8,\n",
    "}\n",
    "data_path = os.path.join('../..', 'data')\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'), dtype=dtype, low_memory=True)\n",
    "test = pd.read_csv(os.path.join(data_path, 'test.csv'), dtype=dtype, low_memory=True)\n",
    "res = pd.read_csv(os.path.join(data_path, 'resources.csv'))\n",
    "\n",
    "print(train.head())\n",
    "# print(test.head())\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "train['project_essay'] = train.apply(lambda row: ' '.join([\n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "test['project_essay'] = test.apply(lambda row: ' '.join([\n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "\n",
    "# Extract features\n",
    "def extract_features(df):\n",
    "    df['project_title_len'] = df['project_title'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_1_len'] = df['project_essay_1'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_2_len'] = df['project_essay_2'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_3_len'] = df['project_essay_3'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_4_len'] = df['project_essay_4'].apply(lambda x: len(str(x)))\n",
    "    df['project_resource_summary_len'] = df['project_resource_summary'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    df['project_title_wc'] = df['project_title'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_1_wc'] = df['project_essay_1'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_2_wc'] = df['project_essay_2'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_3_wc'] = df['project_essay_3'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_4_wc'] = df['project_essay_4'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_resource_summary_wc'] = df['project_resource_summary'].apply(lambda x: len(str(x).split(' ')))\n",
    "  \n",
    "extract_features(train)\n",
    "extract_features(test)\n",
    "\n",
    "train.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4'], axis=1, inplace=True)\n",
    "test.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4'], axis=1, inplace=True)\n",
    "\n",
    "df_all = pd.concat([train, test], axis=0)\n",
    "gc.collect()\n",
    "\n",
    "# Accepted projects counter (gave imrovement on CV but worse on LB, need to be implemented withing a CV loop with splitting data by time)\n",
    "# df_all['project_is_approved'].fillna(0, inplace=True)\n",
    "# cumsums = df_all[\n",
    "#             ['id', \n",
    "#             'teacher_id', \n",
    "#             'project_submitted_datetime', \n",
    "#             'project_is_approved']].\\\n",
    "#         sort_values('project_submitted_datetime').\\\n",
    "#         groupby(['teacher_id']).agg({'project_is_approved': lambda x: x.shift().sum(), 'id': 'first'}).fillna(0).\\\n",
    "#         groupby(level=0).agg({'project_is_approved': 'cumsum', 'id': 'first'}).reset_index()\n",
    "# cumsums = pd.DataFrame(cumsums)\n",
    "# cumsums.rename(columns={'project_is_approved': 'teacher_number_of_previously_accepted_projects'}, inplace=True)\n",
    "# print(cumsums.head())\n",
    "# train = train.merge(cumsums, on=['id', 'teacher_id'], how='left')\n",
    "# test = test.merge(cumsums, on=['id', 'teacher_id'], how='left')\n",
    "\n",
    "# train['approve_rate'] = (train['teacher_number_of_previously_accepted_projects'] + 5)/\\\n",
    "#     (train['teacher_number_of_previously_posted_projects'] + 10)\n",
    "# test['approve_rate'] = (test['teacher_number_of_previously_accepted_projects'] + 5)/\\\n",
    "#     (test['teacher_number_of_previously_posted_projects'] + 10)\n",
    "\n",
    "# print(train.head())\n",
    "# print(test.head())\n",
    "\n",
    "# Merge with resources\n",
    "res = pd.DataFrame(res[['id', 'quantity', 'price']].groupby('id').agg(\\\n",
    "    {\n",
    "        'quantity': [\n",
    "            'sum',\n",
    "            'min', \n",
    "            'max', \n",
    "            'mean', \n",
    "            'std', \n",
    "            # lambda x: len(np.unique(x)),\n",
    "        ],\n",
    "        'price': [\n",
    "            'count', \n",
    "            'sum', \n",
    "            'min', \n",
    "            'max', \n",
    "            'mean', \n",
    "            'std', \n",
    "            lambda x: len(np.unique(x)),\n",
    "        ]}\n",
    "    )).reset_index()\n",
    "res.columns = ['_'.join(col) for col in res.columns]\n",
    "res.rename(columns={'id_': 'id'}, inplace=True)\n",
    "res['mean_price'] = res['price_sum']/res['quantity_sum']\n",
    "# res['price_max_to_price_min'] = res['price_max']/res['price_min']\n",
    "# res['quantity_max_to_quantity_min'] = res['quantity_max']/res['quantity_min']\n",
    "\n",
    "print(res.head())\n",
    "train = train.merge(res, on='id', how='left')\n",
    "test = test.merge(res, on='id', how='left')\n",
    "del res\n",
    "gc.collect()\n",
    "\n",
    "# Preprocess columns with label encoder\n",
    "print('Label Encoder...')\n",
    "cols = [\n",
    "    'teacher_id', \n",
    "    'teacher_prefix', \n",
    "    'school_state', \n",
    "    'project_grade_category', \n",
    "    'project_subject_categories', \n",
    "    'project_subject_subcategories'\n",
    "]\n",
    "\n",
    "for c in tqdm(cols):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_all[c].astype(str))\n",
    "    train[c] = le.transform(train[c].astype(str))\n",
    "    test[c] = le.transform(test[c].astype(str))\n",
    "del le\n",
    "gc.collect()\n",
    "print('Done.')\n",
    "\n",
    "\n",
    "# Preprocess timestamp\n",
    "print('Preprocessing timestamp...')\n",
    "def process_timestamp(df):\n",
    "    df['year'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[0]))\n",
    "    df['month'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[1]))\n",
    "    df['date'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[2]))\n",
    "    df['day_of_week'] = pd.to_datetime(df['project_submitted_datetime']).dt.weekday\n",
    "    df['hour'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[0]))\n",
    "    df['minute'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[1]))\n",
    "    df['project_submitted_datetime'] = pd.to_datetime(df['project_submitted_datetime']).values.astype(np.int64)\n",
    "\n",
    "process_timestamp(train)\n",
    "process_timestamp(test)\n",
    "print('Done.')\n",
    "\n",
    "# Preprocess text\n",
    "print('Preprocessing text...')\n",
    "cols = [\n",
    "    'project_title', \n",
    "    'project_essay', \n",
    "    'project_resource_summary'\n",
    "]\n",
    "n_features = [\n",
    "    400, \n",
    "    4040, \n",
    "    400,\n",
    "]\n",
    "\n",
    "for c_i, c in tqdm(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=n_features[c_i],\n",
    "        norm='l2',\n",
    "        )\n",
    "    tfidf.fit(df_all[c])\n",
    "    tfidf_train = np.array(tfidf.transform(train[c]).toarray(), dtype=np.float16)\n",
    "    tfidf_test = np.array(tfidf.transform(test[c]).toarray(), dtype=np.float16)\n",
    "\n",
    "    for i in range(n_features[c_i]):\n",
    "        train[c + '_tfidf_' + str(i)] = tfidf_train[:, i]\n",
    "        test[c + '_tfidf_' + str(i)] = tfidf_test[:, i]\n",
    "        \n",
    "    del tfidf, tfidf_train, tfidf_test\n",
    "    gc.collect()\n",
    "    \n",
    "print('Done.')\n",
    "del df_all\n",
    "gc.collect()\n",
    "\n",
    "# Prepare data\n",
    "cols_to_drop = [\n",
    "    'id',\n",
    "    'teacher_id',\n",
    "    'project_title', \n",
    "    'project_essay', \n",
    "    'project_resource_summary',\n",
    "    'project_is_approved',\n",
    "]\n",
    "X = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "y = train['project_is_approved']\n",
    "X_test = test.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "id_test = test['id'].values\n",
    "feature_names = list(X.columns)\n",
    "print(X.shape, X_test.shape)\n",
    "\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "# Build the model\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=0)\n",
    "auc_buf = []   \n",
    "\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    print('Fold {}/{}'.format(cnt + 1, n_splits))\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 14,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_threads': 1,\n",
    "        'lambda_l2': 1.0,\n",
    "        'min_gain_to_split': 0,\n",
    "    }  \n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        X.loc[train_index], \n",
    "        y.loc[train_index], \n",
    "        feature_name=feature_names,\n",
    "        )\n",
    "    lgb_train.raw_data = None\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        X.loc[valid_index], \n",
    "        y.loc[valid_index],\n",
    "        )\n",
    "    lgb_valid.raw_data = None\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        for i in range(60):\n",
    "            if i < len(tuples):\n",
    "                print(tuples[i])\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        del importance, model_fnames, tuples\n",
    "\n",
    "    p = model.predict(X.loc[valid_index], num_iteration=model.best_iteration)\n",
    "    auc = roc_auc_score(y.loc[valid_index], p)\n",
    "\n",
    "    print('{} AUC: {}'.format(cnt, auc))\n",
    "\n",
    "    p = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p, dtype=np.float16)\n",
    "    else:\n",
    "        p_buf += np.array(p, dtype=np.float16)\n",
    "    auc_buf.append(auc)\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt > 0: # Comment this to run several folds\n",
    "        break\n",
    "    \n",
    "    del model, lgb_train, lgb_valid, p\n",
    "    gc.collect\n",
    "\n",
    "auc_mean = np.mean(auc_buf)\n",
    "auc_std = np.std(auc_buf)\n",
    "print('AUC = {:.6f} +/- {:.6f}'.format(auc_mean, auc_std))\n",
    "\n",
    "preds = p_buf/cnt\n",
    "\n",
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = id_test\n",
    "subm['project_is_approved'] = preds\n",
    "subm.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
