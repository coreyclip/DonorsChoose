{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
      "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
      "2  p233823  a9b876a9252e08a55e3d894150f75ba3            Ms.           UT   \n",
      "3  p185307  525fdbb6ec7f538a48beebaa0a51b24f            Mr.           NC   \n",
      "4  p013780  a63b5547a7239eae4c1872670848e61a            Mr.           CA   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-11-18 14:45:59          Grades PreK-2   \n",
      "1        2017-04-26 15:57:28             Grades 3-5   \n",
      "2        2017-01-01 22:57:44             Grades 3-5   \n",
      "3        2016-08-12 15:42:11             Grades 3-5   \n",
      "4        2016-08-06 09:09:11             Grades 6-8   \n",
      "\n",
      "            project_subject_categories  \\\n",
      "0                  Literacy & Language   \n",
      "1    Music & The Arts, Health & Sports   \n",
      "2  Math & Science, Literacy & Language   \n",
      "3                      Health & Sports   \n",
      "4                      Health & Sports   \n",
      "\n",
      "            project_subject_subcategories  \\\n",
      "0                                Literacy   \n",
      "1            Performing Arts, Team Sports   \n",
      "2  Applied Sciences, Literature & Writing   \n",
      "3                       Health & Wellness   \n",
      "4                       Health & Wellness   \n",
      "\n",
      "                                       project_title  \\\n",
      "0                           Super Sight Word Centers   \n",
      "1                             Keep Calm and Dance On   \n",
      "2                              Lets 3Doodle to Learn   \n",
      "3  \\\"Kid Inspired\\\" Equipment to Increase Activit...   \n",
      "4   We need clean water for our culinary arts class!   \n",
      "\n",
      "                                     project_essay_1  \\\n",
      "0  Most of my kindergarten students come from low...   \n",
      "1  Our elementary school is a culturally rich sch...   \n",
      "2  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
      "3  My students are the greatest students but are ...   \n",
      "4  My students are athletes and students who are ...   \n",
      "\n",
      "                                     project_essay_2 project_essay_3  \\\n",
      "0  I currently have a differentiated sight word c...             NaN   \n",
      "1  We strive to provide our diverse population of...             NaN   \n",
      "2  We are looking to add some 3Doodler to our cla...             NaN   \n",
      "3  The student's project which is totally \\\"kid-i...             NaN   \n",
      "4  For some reason in our kitchen the water comes...             NaN   \n",
      "\n",
      "  project_essay_4                           project_resource_summary  \\\n",
      "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
      "1             NaN  My students need matching shirts to wear for d...   \n",
      "2             NaN  My students need the 3doodler. We are an SEM s...   \n",
      "3             NaN  My students need balls and other activity equi...   \n",
      "4             NaN  My students need a water filtration system for...   \n",
      "\n",
      "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
      "0                                            26                    1  \n",
      "1                                             1                    0  \n",
      "2                                             5                    1  \n",
      "3                                            16                    0  \n",
      "4                                            42                    1  \n",
      "(182080, 16) (78035, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ucidataanalytics/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:88: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  quantity_sum  quantity_min  quantity_max  quantity_mean  \\\n",
      "0  p000001             7             1             2       1.750000   \n",
      "1  p000002            21             1             4       1.500000   \n",
      "2  p000003             4             1             1       1.000000   \n",
      "3  p000004            98             1             2       1.031579   \n",
      "4  p000005             8             1             3       2.000000   \n",
      "\n",
      "   quantity_std  price_count  price_sum  price_min  price_max  price_mean  \\\n",
      "0      0.500000            4     459.56      23.99     261.08  114.890000   \n",
      "1      0.854850           14     515.89       8.46     134.90   36.849286   \n",
      "2      0.000000            4     298.97      39.99     169.00   74.742500   \n",
      "3      0.175804           95    1113.69       1.60     401.54   11.723053   \n",
      "4      1.154701            4     485.99      54.08     323.75  121.497500   \n",
      "\n",
      "    price_std  price_<lambda>  mean_price  \n",
      "0  101.929679             4.0   65.651429  \n",
      "1   33.549557            13.0   24.566190  \n",
      "2   63.014906             3.0   74.742500  \n",
      "3   40.608577            36.0   11.364184  \n",
      "4  134.835000             2.0   60.748750  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:02<00:10,  2.13s/it]\r",
      " 33%|███▎      | 2/6 [00:02<00:05,  1.26s/it]\r",
      " 50%|█████     | 3/6 [00:02<00:02,  1.01it/s]\r",
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.19it/s]\r",
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.27it/s]\r",
      "100%|██████████| 6/6 [00:04<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Preprocessing timestamp...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.31s/it]\r",
      "2it [03:38, 109.06s/it]\r",
      "3it [04:04, 81.39s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(182080, 4878) (78035, 4878)\n",
      "Fold 1/5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# Load Data\n",
    "dtype = {\n",
    "    'id': str,\n",
    "    'teacher_id': str,\n",
    "    'teacher_prefix': str,\n",
    "    'school_state': str,\n",
    "    'project_submitted_datetime': str,\n",
    "    'project_grade_category': str,\n",
    "    'project_subject_categories': str,\n",
    "    'project_subject_subcategories': str,\n",
    "    'project_title': str,\n",
    "    'project_essay_1': str,\n",
    "    'project_essay_2': str,\n",
    "    'project_essay_3': str,\n",
    "    'project_essay_4': str,\n",
    "    'project_resource_summary': str,\n",
    "    'teacher_number_of_previously_posted_projects': int,\n",
    "    'project_is_approved': np.uint8,\n",
    "}\n",
    "data_path = os.path.join('../..', 'data')\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'), dtype=dtype, low_memory=True)\n",
    "test = pd.read_csv(os.path.join(data_path, 'test.csv'), dtype=dtype, low_memory=True)\n",
    "res = pd.read_csv(os.path.join(data_path, 'resources.csv'))\n",
    "\n",
    "print(train.head())\n",
    "# print(test.head())\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "train['project_essay'] = train.apply(lambda row: ' '.join([\n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "test['project_essay'] = test.apply(lambda row: ' '.join([\n",
    "    str(row['project_essay_1']), \n",
    "    str(row['project_essay_2']), \n",
    "    str(row['project_essay_3']), \n",
    "    str(row['project_essay_4']),\n",
    "    ]), axis=1)\n",
    "\n",
    "# Extract features\n",
    "def extract_features(df):\n",
    "    df['project_title_len'] = df['project_title'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_1_len'] = df['project_essay_1'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_2_len'] = df['project_essay_2'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_3_len'] = df['project_essay_3'].apply(lambda x: len(str(x)))\n",
    "    df['project_essay_4_len'] = df['project_essay_4'].apply(lambda x: len(str(x)))\n",
    "    df['project_resource_summary_len'] = df['project_resource_summary'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    df['project_title_wc'] = df['project_title'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_1_wc'] = df['project_essay_1'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_2_wc'] = df['project_essay_2'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_3_wc'] = df['project_essay_3'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_essay_4_wc'] = df['project_essay_4'].apply(lambda x: len(str(x).split(' ')))\n",
    "    df['project_resource_summary_wc'] = df['project_resource_summary'].apply(lambda x: len(str(x).split(' ')))\n",
    "  \n",
    "extract_features(train)\n",
    "extract_features(test)\n",
    "\n",
    "train.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4'], axis=1, inplace=True)\n",
    "test.drop([\n",
    "    'project_essay_1', \n",
    "    'project_essay_2', \n",
    "    'project_essay_3', \n",
    "    'project_essay_4'], axis=1, inplace=True)\n",
    "\n",
    "df_all = pd.concat([train, test], axis=0)\n",
    "gc.collect()\n",
    "\n",
    "# Accepted projects counter (gave imrovement on CV but worse on LB, need to be implemented withing a CV loop with splitting data by time)\n",
    "# df_all['project_is_approved'].fillna(0, inplace=True)\n",
    "# cumsums = df_all[\n",
    "#             ['id', \n",
    "#             'teacher_id', \n",
    "#             'project_submitted_datetime', \n",
    "#             'project_is_approved']].\\\n",
    "#         sort_values('project_submitted_datetime').\\\n",
    "#         groupby(['teacher_id']).agg({'project_is_approved': lambda x: x.shift().sum(), 'id': 'first'}).fillna(0).\\\n",
    "#         groupby(level=0).agg({'project_is_approved': 'cumsum', 'id': 'first'}).reset_index()\n",
    "# cumsums = pd.DataFrame(cumsums)\n",
    "# cumsums.rename(columns={'project_is_approved': 'teacher_number_of_previously_accepted_projects'}, inplace=True)\n",
    "# print(cumsums.head())\n",
    "# train = train.merge(cumsums, on=['id', 'teacher_id'], how='left')\n",
    "# test = test.merge(cumsums, on=['id', 'teacher_id'], how='left')\n",
    "\n",
    "# train['approve_rate'] = (train['teacher_number_of_previously_accepted_projects'] + 5)/\\\n",
    "#     (train['teacher_number_of_previously_posted_projects'] + 10)\n",
    "# test['approve_rate'] = (test['teacher_number_of_previously_accepted_projects'] + 5)/\\\n",
    "#     (test['teacher_number_of_previously_posted_projects'] + 10)\n",
    "\n",
    "# print(train.head())\n",
    "# print(test.head())\n",
    "\n",
    "# Merge with resources\n",
    "res = pd.DataFrame(res[['id', 'quantity', 'price']].groupby('id').agg(\\\n",
    "    {\n",
    "        'quantity': [\n",
    "            'sum',\n",
    "            'min', \n",
    "            'max', \n",
    "            'mean', \n",
    "            'std', \n",
    "            # lambda x: len(np.unique(x)),\n",
    "        ],\n",
    "        'price': [\n",
    "            'count', \n",
    "            'sum', \n",
    "            'min', \n",
    "            'max', \n",
    "            'mean', \n",
    "            'std', \n",
    "            lambda x: len(np.unique(x)),\n",
    "        ]}\n",
    "    )).reset_index()\n",
    "res.columns = ['_'.join(col) for col in res.columns]\n",
    "res.rename(columns={'id_': 'id'}, inplace=True)\n",
    "res['mean_price'] = res['price_sum']/res['quantity_sum']\n",
    "# res['price_max_to_price_min'] = res['price_max']/res['price_min']\n",
    "# res['quantity_max_to_quantity_min'] = res['quantity_max']/res['quantity_min']\n",
    "\n",
    "print(res.head())\n",
    "train = train.merge(res, on='id', how='left')\n",
    "test = test.merge(res, on='id', how='left')\n",
    "del res\n",
    "gc.collect()\n",
    "\n",
    "# Preprocess columns with label encoder\n",
    "print('Label Encoder...')\n",
    "cols = [\n",
    "    'teacher_id', \n",
    "    'teacher_prefix', \n",
    "    'school_state', \n",
    "    'project_grade_category', \n",
    "    'project_subject_categories', \n",
    "    'project_subject_subcategories'\n",
    "]\n",
    "\n",
    "for c in tqdm(cols):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_all[c].astype(str))\n",
    "    train[c] = le.transform(train[c].astype(str))\n",
    "    test[c] = le.transform(test[c].astype(str))\n",
    "del le\n",
    "gc.collect()\n",
    "print('Done.')\n",
    "\n",
    "\n",
    "# Preprocess timestamp\n",
    "print('Preprocessing timestamp...')\n",
    "def process_timestamp(df):\n",
    "    df['year'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[0]))\n",
    "    df['month'] = df['project_submitted_datetime'].apply(lambda x: int(x.split('-')[1]))\n",
    "    df['date'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[0].split('-')[2]))\n",
    "    df['day_of_week'] = pd.to_datetime(df['project_submitted_datetime']).dt.weekday\n",
    "    df['hour'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[0]))\n",
    "    df['minute'] = df['project_submitted_datetime'].apply(lambda x: int(x.split(' ')[-1].split(':')[1]))\n",
    "    df['project_submitted_datetime'] = pd.to_datetime(df['project_submitted_datetime']).values.astype(np.int64)\n",
    "\n",
    "process_timestamp(train)\n",
    "process_timestamp(test)\n",
    "print('Done.')\n",
    "\n",
    "# Preprocess text\n",
    "print('Preprocessing text...')\n",
    "cols = [\n",
    "    'project_title', \n",
    "    'project_essay', \n",
    "    'project_resource_summary'\n",
    "]\n",
    "n_features = [\n",
    "    400, \n",
    "    4040, \n",
    "    400,\n",
    "]\n",
    "\n",
    "for c_i, c in tqdm(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=n_features[c_i],\n",
    "        norm='l2',\n",
    "        )\n",
    "    tfidf.fit(df_all[c])\n",
    "    tfidf_train = np.array(tfidf.transform(train[c]).toarray(), dtype=np.float16)\n",
    "    tfidf_test = np.array(tfidf.transform(test[c]).toarray(), dtype=np.float16)\n",
    "\n",
    "    for i in range(n_features[c_i]):\n",
    "        train[c + '_tfidf_' + str(i)] = tfidf_train[:, i]\n",
    "        test[c + '_tfidf_' + str(i)] = tfidf_test[:, i]\n",
    "        \n",
    "    del tfidf, tfidf_train, tfidf_test\n",
    "    gc.collect()\n",
    "    \n",
    "print('Done.')\n",
    "del df_all\n",
    "gc.collect()\n",
    "\n",
    "# Prepare data\n",
    "cols_to_drop = [\n",
    "    'id',\n",
    "    'teacher_id',\n",
    "    'project_title', \n",
    "    'project_essay', \n",
    "    'project_resource_summary',\n",
    "    'project_is_approved',\n",
    "]\n",
    "X = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "y = train['project_is_approved']\n",
    "X_test = test.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "id_test = test['id'].values\n",
    "feature_names = list(X.columns)\n",
    "print(X.shape, X_test.shape)\n",
    "\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "# Build the model\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 1\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=0)\n",
    "auc_buf = []   \n",
    "\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    print('Fold {}/{}'.format(cnt + 1, n_splits))\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'max_depth': 14,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.025,\n",
    "        'feature_fraction': 0.85,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "        'num_threads': 1,\n",
    "        'lambda_l2': 1.0,\n",
    "        'min_gain_to_split': 0,\n",
    "    }  \n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        X.loc[train_index], \n",
    "        y.loc[train_index], \n",
    "        feature_name=feature_names,\n",
    "        )\n",
    "    lgb_train.raw_data = None\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        X.loc[valid_index], \n",
    "        y.loc[valid_index],\n",
    "        )\n",
    "    lgb_valid.raw_data = None\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        for i in range(60):\n",
    "            if i < len(tuples):\n",
    "                print(tuples[i])\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        del importance, model_fnames, tuples\n",
    "\n",
    "    p = model.predict(X.loc[valid_index], num_iteration=model.best_iteration)\n",
    "    auc = roc_auc_score(y.loc[valid_index], p)\n",
    "\n",
    "    print('{} AUC: {}'.format(cnt, auc))\n",
    "\n",
    "    p = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p, dtype=np.float16)\n",
    "    else:\n",
    "        p_buf += np.array(p, dtype=np.float16)\n",
    "    auc_buf.append(auc)\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt > 0: # Comment this to run several folds\n",
    "        break\n",
    "    \n",
    "    del model, lgb_train, lgb_valid, p\n",
    "    gc.collect\n",
    "\n",
    "auc_mean = np.mean(auc_buf)\n",
    "auc_std = np.std(auc_buf)\n",
    "print('AUC = {:.6f} +/- {:.6f}'.format(auc_mean, auc_std))\n",
    "\n",
    "preds = p_buf/cnt\n",
    "\n",
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = id_test\n",
    "subm['project_is_approved'] = preds\n",
    "subm.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
